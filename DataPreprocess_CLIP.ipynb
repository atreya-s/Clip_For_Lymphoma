{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZoRD1nfA3AgX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "from PIL import Image\n",
        "import h5py\n",
        "import cv2\n",
        "from typing import *\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "%cd /gdrive/MyDrive/CLIP Images\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zs31QCXy5CtA",
        "outputId": "4ad0fecc-d316-4e56-8ebf-3393329b5ffa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive/MyDrive/CLIP Images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tiff_files = [f for f in os.listdir() if f.endswith('.tiff') or f.endswith('.tif')]"
      ],
      "metadata": {
        "id": "Ydl24HTx5JJy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import h5py\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from typing import Union\n",
        "\n",
        "def preprocess(image: Image.Image, desired_size: int) -> np.ndarray:\n",
        "    img = image.copy()\n",
        "    img.thumbnail((desired_size, desired_size), Image.ANTIALIAS)\n",
        "\n",
        "    new_img = Image.new(\"RGB\", (desired_size, desired_size))\n",
        "    new_img.paste(img, ((desired_size - img.width) // 2, (desired_size - img.height) // 2))\n",
        "\n",
        "    return np.array(new_img)\n",
        "\n",
        "def img_to_hdf5(directory_path: Union[str, os.PathLike], out_filepath: str, resolution: int = 320):\n",
        "    tiff_files = [f for f in os.listdir(directory_path) if f.endswith('.tiff') or f.endswith('.tif')]\n",
        "    dset_size = len(tiff_files)\n",
        "    failed_images = []\n",
        "\n",
        "    if dset_size == 0:\n",
        "        print(\"No TIFF files found in the directory.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {dset_size} TIFF files in the directory.\")\n",
        "\n",
        "    with h5py.File(out_filepath, 'w') as h5f:\n",
        "        img_dset = h5f.create_dataset('cxr', shape=(dset_size, resolution, resolution, 3), dtype=np.uint8)\n",
        "\n",
        "        for idx, filename in enumerate(tqdm(tiff_files)):\n",
        "            try:\n",
        "                img_path = os.path.join(directory_path, filename)\n",
        "\n",
        "                # Read image using Pillow\n",
        "                img = Image.open(img_path).convert('RGB')\n",
        "                print(f\"Processing {img_path}\")\n",
        "\n",
        "                # Preprocess image to desired size\n",
        "                img_array = preprocess(img, desired_size=resolution)\n",
        "                print(f\"Image shape after preprocessing: {img_array.shape}\")\n",
        "\n",
        "                # Check if the image array has the correct shape\n",
        "                assert img_array.shape == (resolution, resolution, 3), f\"Image shape mismatch for {img_path}\"\n",
        "\n",
        "                # Add image to the dataset\n",
        "                img_dset[idx] = img_array\n",
        "                print(f\"Added image {idx + 1} to dataset\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to process {img_path}: {e}\")\n",
        "                failed_images.append((img_path, e))\n",
        "\n",
        "    print(f\"{len(failed_images)} / {dset_size} images failed to be added to the HDF5 file.\")\n",
        "    if failed_images:\n",
        "        print(\"Failed images and errors:\", failed_images)"
      ],
      "metadata": {
        "id": "2J71kQOm9JKT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_to_hdf5('/gdrive/MyDrive/CLIP Images', '/gdrive/MyDrive/CLIP_Images_Dataset.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5K_iJFy_J8U",
        "outputId": "e83cdb91-3e0c-4096-ecf9-68ef82a2f834"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9 TIFF files in the directory.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/9 [00:00<?, ?it/s]<ipython-input-21-e500584d637e>:10: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  img.thumbnail((desired_size, desired_size), Image.ANTIALIAS)\n",
            " 11%|█         | 1/9 [00:00<00:07,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /gdrive/MyDrive/CLIP Images/Copy of sj-03-476_003.tif\n",
            "Image shape after preprocessing: (320, 320, 3)\n",
            "Added image 1 to dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 2/9 [00:01<00:05,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /gdrive/MyDrive/CLIP Images/Copy of sj-03-476_002.tif\n",
            "Image shape after preprocessing: (320, 320, 3)\n",
            "Added image 2 to dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 3/9 [00:02<00:05,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /gdrive/MyDrive/CLIP Images/Copy of sj-03-476_001.tif\n",
            "Image shape after preprocessing: (320, 320, 3)\n",
            "Added image 3 to dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 4/9 [00:03<00:04,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /gdrive/MyDrive/CLIP Images/Copy of sj-05-588-R1_002.tif\n",
            "Image shape after preprocessing: (320, 320, 3)\n",
            "Added image 4 to dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 5/9 [00:04<00:03,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /gdrive/MyDrive/CLIP Images/Copy of sj-05-588-R1_001.tif\n",
            "Image shape after preprocessing: (320, 320, 3)\n",
            "Added image 5 to dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 6/9 [00:04<00:02,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /gdrive/MyDrive/CLIP Images/Copy of sj-05-588-R1_003.tif\n",
            "Image shape after preprocessing: (320, 320, 3)\n",
            "Added image 6 to dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 7/9 [00:05<00:01,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /gdrive/MyDrive/CLIP Images/Copy of sj-04-3077-R2_002.tif\n",
            "Image shape after preprocessing: (320, 320, 3)\n",
            "Added image 7 to dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 8/9 [00:06<00:00,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /gdrive/MyDrive/CLIP Images/Copy of sj-04-3077-R2_003.tif\n",
            "Image shape after preprocessing: (320, 320, 3)\n",
            "Added image 8 to dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:07<00:00,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /gdrive/MyDrive/CLIP Images/Copy of sj-04-3077-R2_001.tif\n",
            "Image shape after preprocessing: (320, 320, 3)\n",
            "Added image 9 to dataset\n",
            "0 / 9 images failed to be added to the HDF5 file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}